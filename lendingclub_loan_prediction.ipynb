{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "_PRNG = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset found, reading preprocessed dataset\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "_DATA_DIR = \"./data\"\n",
    "_FILE_PROCESSED_DATASET = \"lendingclub_2016-2018_processed.csv\"\n",
    "_FILE_PATH_PROCESSED_DATASET = Path(_DATA_DIR + \"/\" + _FILE_PROCESSED_DATASET)\n",
    "\n",
    "_IS_PROCESSED_DATASET = False\n",
    "\n",
    "df = None\n",
    "# Read in the data, check if a preprocessed dataset exists\n",
    "if _FILE_PATH_PROCESSED_DATASET.is_file():\n",
    "    print(\"Preprocessed dataset found, reading preprocessed dataset\")\n",
    "    _IS_PROCESSED_DATASET = True\n",
    "    df = pd.read_csv(_FILE_PATH_PROCESSED_DATASET)\n",
    "else:\n",
    "    # Read all data\n",
    "    print(\"Preprocessed dataset not found, reading all data\")\n",
    "    _dataset_loan_columns = [\"loan_amnt\",\n",
    "                             \"int_rate\",\n",
    "                             \"term\",\n",
    "                             \"grade\",\n",
    "                             \"sub_grade\",\n",
    "                             \"installment\",\n",
    "                             \"annual_inc\",\n",
    "                             \"loan_status\",\n",
    "                             \"verification_status\",\n",
    "                             \"purpose\"]\n",
    "\n",
    "    dataset_loans = {}\n",
    "    for file_name in os.listdir(_DATA_DIR):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            full_file_path = _DATA_DIR + \"/\" + file_name\n",
    "            print(full_file_path)\n",
    "            loan_period = re.search(r'\\d{4}Q[0-4]{1}', file_name).group(0)\n",
    "            dataset_loans[loan_period] = pd.read_csv(full_file_path, usecols=_dataset_loan_columns)[_dataset_loan_columns]\n",
    "    \n",
    "    # Combine all the data into a single dataframe\n",
    "    print(\"Combining all the data into a single dataframe\")\n",
    "    for k, dataset in dataset_loans.items():\n",
    "        if df is None:\n",
    "            df = dataset\n",
    "            continue\n",
    "        df = df.append(dataset, ignore_index=True)\n",
    "\n",
    "    del dataset_loans\n",
    "        \n",
    "    # Convert column types\n",
    "    print(\"Converting column types\")\n",
    "    df[\"loan_amnt\"] = df[\"loan_amnt\"].astype(int)\n",
    "    df[\"annual_inc\"] = df[\"annual_inc\"].astype(int)\n",
    "    df[\"int_rate\"] = df[\"int_rate\"].apply(lambda int_rate: float(int_rate[:-1]))\n",
    "    df[\"term\"] = df[\"term\"].apply(lambda term: int(re.search(r'\\d+', term).group(0)))\n",
    "    \n",
    "    # Remove outliers\n",
    "    # Annual income must be greater than 0 and less than 1 million\n",
    "    # Assume 0 is an outlier\n",
    "    # Assume millioniare+ are outliers\n",
    "    print(\"Removing outliers\")\n",
    "    df = df.loc[(df[\"annual_inc\"] > 0) & (df[\"annual_inc\"] < 1000000)]\n",
    "    \n",
    "    # Convert non-ordinal categorical variables to binary vectors\n",
    "    print(\"Convert non-ordinal categorical variables to binary vectors (this can take a while)\")\n",
    "    total_columns_to_process = len(df[\"verification_status\"].unique()) + len(df[\"purpose\"].unique())\n",
    "    columns_processed = 0\n",
    "    for verification_status in df[\"verification_status\"].unique():\n",
    "        columns_processed += 1\n",
    "        print(f\"[{columns_processed}/{total_columns_to_process}]\", verification_status)\n",
    "        df[\"vs_\" + verification_status] = df.apply(lambda row: int(row[\"verification_status\"] == verification_status), axis=1)\n",
    "    for purpose in df[\"purpose\"].unique():\n",
    "        columns_processed += 1\n",
    "        print(f\"[{columns_processed}/{total_columns_to_process}]\", purpose)\n",
    "        df[\"p_\" + purpose] = df.apply(lambda row: int(row[\"purpose\"] == purpose), axis=1)\n",
    "\n",
    "    df.drop(columns=[\"verification_status\"], inplace=True)\n",
    "    df.drop(columns=[\"purpose\"], inplace=True)\n",
    "    \n",
    "    # Save processed dataset for future use\n",
    "    print(\"Saving processed dataset\")\n",
    "    df.to_csv(_FILE_PATH_PROCESSED_DATASET, index=False, header=True)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loans in combined dataset: 1371066\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>vs_Source Verified</th>\n",
       "      <th>vs_Verified</th>\n",
       "      <th>...</th>\n",
       "      <th>p_other</th>\n",
       "      <th>p_major_purchase</th>\n",
       "      <th>p_vacation</th>\n",
       "      <th>p_moving</th>\n",
       "      <th>p_medical</th>\n",
       "      <th>p_car</th>\n",
       "      <th>p_house</th>\n",
       "      <th>p_renewable_energy</th>\n",
       "      <th>p_wedding</th>\n",
       "      <th>p_educational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>17.27</td>\n",
       "      <td>36</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "      <td>178.94</td>\n",
       "      <td>62000</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22000</td>\n",
       "      <td>6.49</td>\n",
       "      <td>36</td>\n",
       "      <td>A</td>\n",
       "      <td>A2</td>\n",
       "      <td>674.18</td>\n",
       "      <td>134000</td>\n",
       "      <td>Current</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>10.75</td>\n",
       "      <td>60</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>648.54</td>\n",
       "      <td>125000</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>16.29</td>\n",
       "      <td>36</td>\n",
       "      <td>D</td>\n",
       "      <td>D1</td>\n",
       "      <td>353.01</td>\n",
       "      <td>40000</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12000</td>\n",
       "      <td>9.75</td>\n",
       "      <td>36</td>\n",
       "      <td>B</td>\n",
       "      <td>B3</td>\n",
       "      <td>385.80</td>\n",
       "      <td>120000</td>\n",
       "      <td>Current</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  term grade sub_grade  installment  annual_inc  \\\n",
       "0       5000     17.27    36     D        D2       178.94       62000   \n",
       "1      22000      6.49    36     A        A2       674.18      134000   \n",
       "2      30000     10.75    60     B        B4       648.54      125000   \n",
       "3      10000     16.29    36     D        D1       353.01       40000   \n",
       "4      12000      9.75    36     B        B3       385.80      120000   \n",
       "\n",
       "   loan_status  vs_Source Verified  vs_Verified  ...  p_other  \\\n",
       "0   Fully Paid                   1            0  ...        0   \n",
       "1      Current                   0            1  ...        0   \n",
       "2   Fully Paid                   0            1  ...        0   \n",
       "3  Charged Off                   1            0  ...        0   \n",
       "4      Current                   0            0  ...        0   \n",
       "\n",
       "   p_major_purchase  p_vacation  p_moving  p_medical  p_car  p_house  \\\n",
       "0                 0           0         0          0      0        0   \n",
       "1                 0           0         0          0      0        0   \n",
       "2                 0           0         0          0      0        0   \n",
       "3                 0           0         0          0      0        0   \n",
       "4                 0           0         0          0      0        0   \n",
       "\n",
       "   p_renewable_energy  p_wedding  p_educational  \n",
       "0                   0          0              0  \n",
       "1                   0          0              0  \n",
       "2                   0          0              0  \n",
       "3                   0          0              0  \n",
       "4                   0          0              0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of loans in combined dataset:\", len(df))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>vs_Source Verified</th>\n",
       "      <th>vs_Verified</th>\n",
       "      <th>...</th>\n",
       "      <th>p_other</th>\n",
       "      <th>p_major_purchase</th>\n",
       "      <th>p_vacation</th>\n",
       "      <th>p_moving</th>\n",
       "      <th>p_medical</th>\n",
       "      <th>p_car</th>\n",
       "      <th>p_house</th>\n",
       "      <th>p_renewable_energy</th>\n",
       "      <th>p_wedding</th>\n",
       "      <th>p_educational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [loan_amnt, int_rate, term, grade, sub_grade, installment, annual_inc, loan_status, vs_Source Verified, vs_Verified, vs_Not Verified, p_credit_card, p_debt_consolidation, p_small_business, p_home_improvement, p_other, p_major_purchase, p_vacation, p_moving, p_medical, p_car, p_house, p_renewable_energy, p_wedding, p_educational]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if we have any null values\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ordinal categorical variables to numerical\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "\n",
    "le_grade = LabelEncoder()\n",
    "df[\"grade\"] = le_grade.fit_transform(df[\"grade\"])\n",
    "\n",
    "le_sub_grade = LabelEncoder()\n",
    "df[\"sub_grade\"] = le_sub_grade.fit_transform(df[\"sub_grade\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df.loc[df[\"loan_status\"] == \"Fully Paid\"]\n",
    "df_neg = df.loc[(df[\"loan_status\"] == \"Default\") | (df[\"loan_status\"] == \"Charged Off\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid    382014\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Charged Off    108758\n",
       "Default            35\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117732</td>\n",
       "      <td>0.353937</td>\n",
       "      <td>0.114210</td>\n",
       "      <td>0.116027</td>\n",
       "      <td>0.958982</td>\n",
       "      <td>0.422926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <td>0.117732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368597</td>\n",
       "      <td>0.962965</td>\n",
       "      <td>0.987197</td>\n",
       "      <td>0.155487</td>\n",
       "      <td>-0.099715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>0.353937</td>\n",
       "      <td>0.368597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357490</td>\n",
       "      <td>0.366070</td>\n",
       "      <td>0.136393</td>\n",
       "      <td>0.079493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>0.114210</td>\n",
       "      <td>0.962965</td>\n",
       "      <td>0.357490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971276</td>\n",
       "      <td>0.148621</td>\n",
       "      <td>-0.099893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade</th>\n",
       "      <td>0.116027</td>\n",
       "      <td>0.987197</td>\n",
       "      <td>0.366070</td>\n",
       "      <td>0.971276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151058</td>\n",
       "      <td>-0.108120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>0.958982</td>\n",
       "      <td>0.155487</td>\n",
       "      <td>0.136393</td>\n",
       "      <td>0.148621</td>\n",
       "      <td>0.151058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.403238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>0.422926</td>\n",
       "      <td>-0.099715</td>\n",
       "      <td>0.079493</td>\n",
       "      <td>-0.099893</td>\n",
       "      <td>-0.108120</td>\n",
       "      <td>0.403238</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             loan_amnt  int_rate      term     grade  sub_grade  installment  \\\n",
       "loan_amnt     1.000000  0.117732  0.353937  0.114210   0.116027     0.958982   \n",
       "int_rate      0.117732  1.000000  0.368597  0.962965   0.987197     0.155487   \n",
       "term          0.353937  0.368597  1.000000  0.357490   0.366070     0.136393   \n",
       "grade         0.114210  0.962965  0.357490  1.000000   0.971276     0.148621   \n",
       "sub_grade     0.116027  0.987197  0.366070  0.971276   1.000000     0.151058   \n",
       "installment   0.958982  0.155487  0.136393  0.148621   0.151058     1.000000   \n",
       "annual_inc    0.422926 -0.099715  0.079493 -0.099893  -0.108120     0.403238   \n",
       "\n",
       "             annual_inc  \n",
       "loan_amnt      0.422926  \n",
       "int_rate      -0.099715  \n",
       "term           0.079493  \n",
       "grade         -0.099893  \n",
       "sub_grade     -0.108120  \n",
       "installment    0.403238  \n",
       "annual_inc     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos[[\"loan_amnt\", \"int_rate\", \"term\", \"grade\", \"sub_grade\", \"installment\", \"annual_inc\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191178</td>\n",
       "      <td>0.387081</td>\n",
       "      <td>0.187644</td>\n",
       "      <td>0.193173</td>\n",
       "      <td>0.945589</td>\n",
       "      <td>0.450970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <td>0.191178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.376418</td>\n",
       "      <td>0.962659</td>\n",
       "      <td>0.983896</td>\n",
       "      <td>0.248679</td>\n",
       "      <td>-0.066134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>0.387081</td>\n",
       "      <td>0.376418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372196</td>\n",
       "      <td>0.383811</td>\n",
       "      <td>0.142168</td>\n",
       "      <td>0.109504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>0.187644</td>\n",
       "      <td>0.962659</td>\n",
       "      <td>0.372196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.238671</td>\n",
       "      <td>-0.068205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade</th>\n",
       "      <td>0.193173</td>\n",
       "      <td>0.983896</td>\n",
       "      <td>0.383811</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244191</td>\n",
       "      <td>-0.070253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>0.945589</td>\n",
       "      <td>0.248679</td>\n",
       "      <td>0.142168</td>\n",
       "      <td>0.238671</td>\n",
       "      <td>0.244191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>0.450970</td>\n",
       "      <td>-0.066134</td>\n",
       "      <td>0.109504</td>\n",
       "      <td>-0.068205</td>\n",
       "      <td>-0.070253</td>\n",
       "      <td>0.419332</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             loan_amnt  int_rate      term     grade  sub_grade  installment  \\\n",
       "loan_amnt     1.000000  0.191178  0.387081  0.187644   0.193173     0.945589   \n",
       "int_rate      0.191178  1.000000  0.376418  0.962659   0.983896     0.248679   \n",
       "term          0.387081  0.376418  1.000000  0.372196   0.383811     0.142168   \n",
       "grade         0.187644  0.962659  0.372196  1.000000   0.975763     0.238671   \n",
       "sub_grade     0.193173  0.983896  0.383811  0.975763   1.000000     0.244191   \n",
       "installment   0.945589  0.248679  0.142168  0.238671   0.244191     1.000000   \n",
       "annual_inc    0.450970 -0.066134  0.109504 -0.068205  -0.070253     0.419332   \n",
       "\n",
       "             annual_inc  \n",
       "loan_amnt      0.450970  \n",
       "int_rate      -0.066134  \n",
       "term           0.109504  \n",
       "grade         -0.068205  \n",
       "sub_grade     -0.070253  \n",
       "installment    0.419332  \n",
       "annual_inc     1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg[[\"loan_amnt\", \"int_rate\", \"term\", \"grade\", \"sub_grade\", \"installment\", \"annual_inc\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample pos: 100000\n",
      "Subsample neg: 100000\n"
     ]
    }
   ],
   "source": [
    "# Take a random even subsample\n",
    "SUBSAMPLE_AMOUNT = 100000\n",
    "\n",
    "df_pos = df_pos.sample(n=SUBSAMPLE_AMOUNT, replace=False, random_state=_PRNG)\n",
    "df_neg = df_neg.sample(n=SUBSAMPLE_AMOUNT, replace=False, random_state=_PRNG)\n",
    "\n",
    "df_pos.drop(columns=[\"loan_status\"], inplace=True)\n",
    "df_neg.drop(columns=[\"loan_status\"], inplace=True)\n",
    "print(\"Subsample pos:\", len(df_pos))\n",
    "print(\"Subsample neg:\", len(df_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine subsamples\n",
    "df_subsample_X = pd.concat([df_pos, df_neg], ignore_index=True, copy=True)\n",
    "df_subsample_X = df_subsample_X.astype(float)\n",
    "df_subsample_Y = [1] * len(df_pos) + [0] * len(df_neg)\n",
    "\n",
    "assert len(df_subsample_X) == len(df_subsample_Y), \"Dataset and labels must be the same size\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most libraries recommend a hard normalization, mapping the min and max values of a given dimension to [0,1]\n",
    "# However, a soft normalization is also feasible using StandardScaler\n",
    "# https://neerajkumar.org/writings/svm/\n",
    "# https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "df_subsample_scaled_X = scaler.fit_transform(df_subsample_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "# The training set is much smaller due to computation constraints, SVMs have poor scalability\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_subsample_scaled_X, df_subsample_Y, train_size=0.1, test_size=0.2, stratify=df_subsample_Y, random_state=_PRNG)\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Training label size:\", len(Y_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "print(\"Test label size:\", len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use grid search cross-validation to find the best C, using F1-score\n",
    "parameters = {\n",
    "    \"C\" : [2 ** power for power in range(-5, 9)]\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"C\" : [0.0625]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(SVC(kernel=\"linear\", cache_size=4000, probability=True, random_state=_PRNG), param_grid=parameters, scoring=\"f1\", cv=5, refit=True, n_jobs=-1, verbose=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "print (clf.best_score_, clf.best_params_)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = clf.best_estimator_\n",
    "\n",
    "svm.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col_name, value in zip(df_pos.columns, svm.coef_.ravel()):\n",
    "    print(\"{:20s} : {:.4f}\".format(col_name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot SVM feature weights\n",
    "coef = svm.coef_.ravel()\n",
    "coef_sorted = np.argsort(coef)[::-1]\n",
    "\n",
    "col = list(df_pos.columns)\n",
    "colors = [\"lightcoral\" if feature_weight < 0 else \"lightgreen\" for feature_weight in coef[coef_sorted]]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.bar(list(range(len(coef))), coef[coef_sorted], color=colors)\n",
    "plt.xticks(np.arange(0, len(coef)), [col[idx] for idx in coef_sorted], rotation=60, ha=\"right\")\n",
    "plt.xlabel(\"Feature Name\")\n",
    "plt.ylabel(\"Feature Weight\")\n",
    "plt.title(\"LendingClub 2016-2018 - SVM Feature Weights\")\n",
    "plt.savefig(\"res/Prediction/SVM - Feature Weights.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm.predict_proba(X_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_subsample_scaled_X = scaler.fit_transform(df_subsample_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_subsample_scaled_X, df_subsample_Y, test_size=0.125, stratify=df_subsample_Y, random_state=_PRNG)\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Training label size:\", len(Y_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "print(\"Test label size:\", len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use random search to find best hyperparameters\n",
    "parameters = {\n",
    "    \"max_depth\"             : range(1, 31),\n",
    "    \"min_samples_split\"     : range(2, 21),\n",
    "    \"min_samples_leaf\"      : range(1, 11),\n",
    "    \"min_impurity_decrease\" : np.arange(0, 0.05, 0.002),\n",
    "    \"max_features\"          : [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"max_depth\"             : range(1, 11),\n",
    "    \"max_features\"          : [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(DecisionTreeClassifier(criterion=\"gini\", random_state=_PRNG), param_distributions=parameters, n_iter=250, scoring=\"f1\", cv=5, refit=True, n_jobs=-1, random_state=_PRNG, verbose=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(clf.best_score_, clf.best_params_)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = clf.best_estimator_\n",
    "\n",
    "decision_tree.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree.predict_proba(X_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_subsample_scaled_X = scaler.fit_transform(df_subsample_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 175000\n",
      "Training label size: 175000\n",
      "Test set size: 25000\n",
      "Test label size: 25000\n"
     ]
    }
   ],
   "source": [
    "# Create train/test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_subsample_scaled_X, df_subsample_Y, test_size=0.125, stratify=df_subsample_Y, random_state=_PRNG)\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Training label size:\", len(Y_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "print(\"Test label size:\", len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juszhan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 3 is smaller than n_iter=250. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   25.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5922970199090193 {'max_features': 'sqrt', 'max_depth': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=1, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False,\n",
       "            random_state=<mtrand.RandomState object at 0x00000261D8ABB558>,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use random search to find best hyperparameters\n",
    "parameters = {\n",
    "    \"n_estimators\"          : range(10, 200, 10),\n",
    "    \"max_depth\"             : range(1, 31),\n",
    "    \"min_samples_split\"     : range(2, 21),\n",
    "    \"min_samples_leaf\"      : range(1, 11),\n",
    "    \"min_impurity_decrease\" : np.arange(0, 0.05, 0.002),\n",
    "    \"max_features\"          : [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"max_depth\"             : range(1, 2),\n",
    "    \"max_features\"          : [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(RandomForestClassifier(n_estimators=100, criterion=\"gini\", n_jobs=-1, random_state=_PRNG), param_distributions=parameters, n_iter=250, scoring=\"f1\", cv=5, refit=True, n_jobs=-1, random_state=_PRNG, verbose=1)\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(clf.best_score_, clf.best_params_)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63784"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = clf.best_estimator_\n",
    "\n",
    "random_forest.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41698937, 0.58301063],\n",
       "       [0.54554798, 0.45445202],\n",
       "       [0.54718403, 0.45281597],\n",
       "       [0.44906729, 0.55093271],\n",
       "       [0.42957291, 0.57042709],\n",
       "       [0.54483287, 0.45516713],\n",
       "       [0.41139824, 0.58860176],\n",
       "       [0.42393509, 0.57606491],\n",
       "       [0.57462066, 0.42537934],\n",
       "       [0.58081604, 0.41918396]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.predict_proba(X_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_subsample_scaled_X = scaler.fit_transform(df_subsample_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 175000\n",
      "Training label size: 175000\n",
      "Test set size: 25000\n",
      "Test label size: 25000\n"
     ]
    }
   ],
   "source": [
    "# Create train/test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_subsample_scaled_X, df_subsample_Y, test_size=0.125, stratify=df_subsample_Y, random_state=_PRNG)\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Training label size:\", len(Y_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "print(\"Test label size:\", len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juszhan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 3 is smaller than n_iter=250. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6329155660875708 {'max_features': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=30, presort='auto',\n",
       "              random_state=<mtrand.RandomState object at 0x0000026190DBC3A8>,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use random search to find best hyperparameters\n",
    "parameters = {\n",
    "    \"learning_rate\"         : np.arange(.001, .2, 0.002),\n",
    "    \"subsample\"             : np.arange(.5, 1.0, 0.1),\n",
    "    \"max_depth\"             : range(1, 31),\n",
    "    \"min_samples_split\"     : range(2, 21),\n",
    "    \"min_samples_leaf\"      : range(1, 11),\n",
    "    \"max_depth\"             : range(3, 10),\n",
    "    \"min_impurity_decrease\" : np.arange(0, 0.05, 0.002),\n",
    "    \"max_features\"          : [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"max_features\"          : [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(GradientBoostingClassifier(loss=\"deviance\", n_estimators=100, random_state=_PRNG, n_iter_no_change=30, validation_fraction=0.1, tol=1e-4), param_distributions=parameters, n_iter=250, scoring=\"f1\", cv=5, refit=True, n_jobs=-1, random_state=_PRNG, verbose=1)\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(clf.best_score_, clf.best_params_)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64112"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boosting = clf.best_estimator_\n",
    "\n",
    "gradient_boosting.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55299676, 0.44700324],\n",
       "       [0.80681415, 0.19318585],\n",
       "       [0.69360901, 0.30639099],\n",
       "       [0.29439012, 0.70560988],\n",
       "       [0.47558811, 0.52441189],\n",
       "       [0.46292108, 0.53707892],\n",
       "       [0.59270883, 0.40729117],\n",
       "       [0.81502597, 0.18497403],\n",
       "       [0.52222615, 0.47777385],\n",
       "       [0.39565172, 0.60434828]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boosting.predict_proba(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
